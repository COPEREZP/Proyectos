{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23ccd113-2f93-4eaf-92b9-73e705be8903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo: C:\\Users\\constanza.perez\\OneDrive - Colgram\\Escritorio\\2025 COLLOKY F.csv - Cantidad de filas: 317329\n",
      "Archivo: C:\\Users\\constanza.perez\\OneDrive - Colgram\\Escritorio\\2024 COLLOKY F.csv - Cantidad de filas: 4133983\n",
      "Archivo: C:\\Users\\constanza.perez\\OneDrive - Colgram\\Escritorio\\2023 COLLOKY 2.csv - Cantidad de filas: 3766863\n",
      "Archivo: C:\\Users\\constanza.perez\\OneDrive - Colgram\\Escritorio\\2022 COLLOKY 2.csv - Cantidad de filas: 3885629\n",
      "Archivo: C:\\Users\\constanza.perez\\OneDrive - Colgram\\Escritorio\\2021 COLLOKY 2.csv - Cantidad de filas: 4124811\n",
      "Archivo: C:\\Users\\constanza.perez\\OneDrive - Colgram\\Escritorio\\2020 COLLOKY 2.csv - Cantidad de filas: 3379862\n",
      "Archivo: C:\\Users\\constanza.perez\\OneDrive - Colgram\\Escritorio\\2019 COLLOKY 2.csv - Cantidad de filas: 4777794\n",
      "Archivo: C:\\Users\\constanza.perez\\OneDrive - Colgram\\Escritorio\\2016 COLLOKY 2.csv - Cantidad de filas: 2393628\n",
      "Archivo: C:\\Users\\constanza.perez\\OneDrive - Colgram\\Escritorio\\2017 COLLOKY 2.csv - Cantidad de filas: 3340206\n",
      "Archivo: C:\\Users\\constanza.perez\\OneDrive - Colgram\\Escritorio\\2018 COLLOKY 2.csv - Cantidad de filas: 4299622\n",
      "\n",
      "Cantidad total de filas en el DataFrame unificado: 34419727 - Cantidad total de columnas: 17\n",
      "Nombres de las columnas en minúsculas: ['fecha', 'boleta', 'montoneto', 'marca', 'sku', 'cantidad', 'area', 'temporada', 'correo', 'genero', 'canal', 'edad', 'preciolleno', 'edad_meses_talla_hoy', 'edad_ano_talla_hoy', 'rut', 'cod_tienda']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Definir las rutas de los archivos CSV\n",
    "archivos_csv = [\n",
    "       r\"C:\\Users\\constanza.perez\\OneDrive - Colgram\\Escritorio\\2025 COLLOKY F.csv\",\n",
    "    r\"C:\\Users\\constanza.perez\\OneDrive - Colgram\\Escritorio\\2024 COLLOKY F.csv\",\n",
    "    r\"C:\\Users\\constanza.perez\\OneDrive - Colgram\\Escritorio\\2023 COLLOKY 2.csv\",\n",
    "    r\"C:\\Users\\constanza.perez\\OneDrive - Colgram\\Escritorio\\2022 COLLOKY 2.csv\",\n",
    "    r\"C:\\Users\\constanza.perez\\OneDrive - Colgram\\Escritorio\\2021 COLLOKY 2.csv\",\n",
    "    r\"C:\\Users\\constanza.perez\\OneDrive - Colgram\\Escritorio\\2020 COLLOKY 2.csv\",\n",
    "    r\"C:\\Users\\constanza.perez\\OneDrive - Colgram\\Escritorio\\2019 COLLOKY 2.csv\",\n",
    "    r\"C:\\Users\\constanza.perez\\OneDrive - Colgram\\Escritorio\\2016 COLLOKY 2.csv\",\n",
    "    r\"C:\\Users\\constanza.perez\\OneDrive - Colgram\\Escritorio\\2017 COLLOKY 2.csv\",\n",
    "    r\"C:\\Users\\constanza.perez\\OneDrive - Colgram\\Escritorio\\2018 COLLOKY 2.csv\"\n",
    "]\n",
    "\n",
    "# Leer cada archivo CSV y almacenar en una lista\n",
    "dfs = []\n",
    "for archivo in archivos_csv:\n",
    "    df_temp = pd.read_csv(archivo, low_memory=False)  # Cargar el CSV con low_memory=False\n",
    "    \n",
    "    # Convertir todos los nombres de columnas a minúsculas\n",
    "    df_temp.columns = df_temp.columns.str.lower()\n",
    "    \n",
    "    dfs.append(df_temp)\n",
    "    \n",
    "    # Imprimir el conteo de filas de cada archivo CSV\n",
    "    print(f'Archivo: {archivo} - Cantidad de filas: {df_temp.shape[0]}')\n",
    "\n",
    "# Unir todos los DataFrames en uno solo\n",
    "df_unificado = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Imprimir la cantidad total de filas y columnas del DataFrame unificado\n",
    "print(f'\\nCantidad total de filas en el DataFrame unificado: {df_unificado.shape[0]} - Cantidad total de columnas: {df_unificado.shape[1]}')\n",
    "\n",
    "# Verificar los nombres de las columnas en minúsculas\n",
    "print(f'Nombres de las columnas en minúsculas: {list(df_unificado.columns)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09c9b584-386b-472a-b05b-423c243d4412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conteo de filas antes del cambio: 34419727\n",
      "Conteo de filas después del cambio: 34036726\n"
     ]
    }
   ],
   "source": [
    "# Lista de valores a eliminar\n",
    "valores_a_eliminar = [\n",
    "    'BOLSACHICKYTT', 'BOLSACHCKY50A', 'BOLSACHCKYNAV', 'BOLSACHOPALTT', 'BOLSAGRCKY50A', \n",
    "    'BOLSAGRCKYNAV', 'BOLSAGRACKYTT', 'BOLSAGROPALTT', 'BOLSAMEDCK50A', 'BOLSAMEDCKNAV', \n",
    "    'BOLSAMEDCKYTT', 'BOLSAMEDOPATT', 'BOLXJ701450OP'\n",
    "]\n",
    "\n",
    "# Conteo de filas antes de eliminar\n",
    "conteo_filas_antes = len(df_unificado)\n",
    "\n",
    "# Eliminar las filas donde la columna 'sku' tenga cualquiera de los valores en la lista\n",
    "df_unificado = df_unificado[~df_unificado['sku'].isin(valores_a_eliminar)]\n",
    "\n",
    "# Conteo de filas después de eliminar\n",
    "conteo_filas_despues = len(df_unificado)\n",
    "\n",
    "# Imprimir el conteo de filas antes y después\n",
    "print(f\"Conteo de filas antes del cambio: {conteo_filas_antes}\")\n",
    "print(f\"Conteo de filas después del cambio: {conteo_filas_despues}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85beee1f-0159-4b91-952a-b03c538656ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fecha convertida a datetime:\n",
      "0   2025-02-02\n",
      "1   2025-01-04\n",
      "2   2025-02-02\n",
      "3   2025-01-07\n",
      "4   2025-01-08\n",
      "Name: fecha, dtype: datetime64[ns]\n",
      "RUTs convertidos a minúsculas:\n",
      "0    15172914-2\n",
      "1    15362705-3\n",
      "2    13645170-7\n",
      "3    16925597-0\n",
      "4    17918455-9\n",
      "Name: rut, dtype: object\n",
      "RUTs en el mes base:\n",
      "['15362705-3' '16925597-0' '17918455-9' '15156193-4' '16611410-1'\n",
      " '17859148-7' '13015631-2' '18430776-6' '16621278-2' '16211366-6']\n",
      "Primera fecha de compra por RUT en el período base:\n",
      "          rut      fecha mes_fecha_min\n",
      "0      10000- 2025-01-08    2025-01-08\n",
      "1  10000017-2 2024-07-05    2024-07-05\n",
      "2  10000020-2 2024-06-10    2024-06-10\n",
      "3  10000039-3 2024-08-18    2024-08-18\n",
      "4  10000040-7 2024-02-24    2024-02-24\n",
      "Datos después del merge con fechas mínimas:\n",
      "       fecha            boleta  montoneto    marca            sku  cantidad  \\\n",
      "0 2025-02-02  1507824429584-01    2114.29  COLLOKY  P1JE41508AV24         1   \n",
      "1 2025-01-04  2000006954943589   15537.82  COLLOKY  7177020126I23         1   \n",
      "2 2025-02-02  1507934430144-01    5037.82  COLLOKY  P1JE19706AV25         1   \n",
      "3 2025-01-07        2691638672   15957.98  COLLOKY  5781021031V25         1   \n",
      "4 2025-01-08  1501824414091-01    2685.71  COLLOKY  C1PE021056I24         1   \n",
      "\n",
      "         area     temporada                      correo genero   canal  edad  \\\n",
      "0        ROPA    VERANO2024        lissburver@gmail.com    BOY  ONLINE  38.0   \n",
      "1     CALZADO  INVIERNO2023           21330306@meli.com    BOY  ONLINE  37.0   \n",
      "2        ROPA    VERANO2025  yuvitzabenavides@gmail.com    BOY  ONLINE  43.0   \n",
      "3     CALZADO    VERANO2025      2691638672@ecomsur.com    BOY  ONLINE  32.0   \n",
      "4  ACCESORIOS  INVIERNO2024    k.llanquileo01@gmail.com   GIRL  ONLINE  29.0   \n",
      "\n",
      "   preciolleno  edad_meses_talla_hoy  edad_ano_talla_hoy         rut  \\\n",
      "0       6990.0                  96.0                 8.0  15172914-2   \n",
      "1      36990.0                  49.0                 4.0  15362705-3   \n",
      "2      11990.0                   NaN                 NaN  13645170-7   \n",
      "3      37990.0                   NaN                 NaN  16925597-0   \n",
      "4       7990.0                  61.0                 5.0  17918455-9   \n",
      "\n",
      "   cod_tienda mes_fecha_min  \n",
      "0         184    2024-02-19  \n",
      "1         184    2025-01-04  \n",
      "2         184    2024-08-08  \n",
      "3         184    2024-05-02  \n",
      "4         184    2024-06-25  \n",
      "Datos filtrados con fechas anteriores a la primera compra:\n",
      "            fecha            boleta  montoneto    marca            sku  \\\n",
      "255982 2024-01-05  1401133937159-01    11591.6  COLLOKY  5334108429V23   \n",
      "256012 2024-01-23          25390337    25201.0  COLLOKY  7705023034I24   \n",
      "256036 2024-01-10          25340244    14109.0  COLLOKY  4304028225V24   \n",
      "256092 2024-01-13          25297287    10075.0  COLLOKY  JOGB0350MEV24   \n",
      "256120 2024-01-18          25387685     5037.0  COLLOKY  POJE59503AI24   \n",
      "\n",
      "        cantidad        area     temporada                       correo  \\\n",
      "255982         1     CALZADO    VERANO2023     yessitaa.tapia@gmail.com   \n",
      "256012         1     CALZADO  INVIERNO2024  blancarodrivaldes@gmail.com   \n",
      "256036         1     CALZADO    VERANO2024      mariagaete834@gmail.com   \n",
      "256092         1  ACCESORIOS    VERANO2024    paulina.silva83@gmail.com   \n",
      "256120         1        ROPA  INVIERNO2024         dakampos26@gmail.com   \n",
      "\n",
      "            genero    canal  edad  preciolleno  edad_meses_talla_hoy  \\\n",
      "255982        GIRL   ONLINE  31.0     22990.00                  78.0   \n",
      "256012  Sin Genero  OFFLINE  42.0     29989.19                 120.0   \n",
      "256036        GIRL  OFFLINE  63.0     16789.71                  57.0   \n",
      "256092         BOY  OFFLINE  39.0     11989.25                  96.0   \n",
      "256120         BOY  OFFLINE  27.0      5994.03                  48.0   \n",
      "\n",
      "        edad_ano_talla_hoy         rut  cod_tienda mes_fecha_min  \n",
      "255982                 7.0  17282887-6         184    2024-06-02  \n",
      "256012                10.0  14120760-1         108    2024-03-06  \n",
      "256036                 5.0   7772256-4         170    2024-12-02  \n",
      "256092                 8.0  15010047-k         131    2024-03-03  \n",
      "256120                 4.0  18523408-8         144    2024-03-09  \n",
      "Máxima fecha anterior a la primera compra por RUT:\n",
      "          rut  seg_fecha\n",
      "0  10000017-2 2023-07-04\n",
      "1  10000020-2 2021-12-16\n",
      "2  10000039-3 2023-11-12\n",
      "3  10000040-7 2023-02-14\n",
      "4  10000048-2 2023-11-22\n",
      "Datos después del segundo merge:\n",
      "          rut  seg_fecha mes_fecha_min\n",
      "0  10000017-2 2023-07-04    2024-07-05\n",
      "1  10000020-2 2021-12-16    2024-06-10\n",
      "2  10000039-3 2023-11-12    2024-08-18\n",
      "3  10000040-7 2023-02-14    2024-02-24\n",
      "4  10000048-2 2023-11-22    2024-07-21\n",
      "Datos con clasificación de clientes:\n",
      "          rut  seg_fecha mes_fecha_min       clasificacion_cliente\n",
      "0  10000017-2 2023-07-04    2024-07-05  Cliente Antiguo Recuperado\n",
      "1  10000020-2 2021-12-16    2024-06-10     Cliente Antiguo Perdido\n",
      "2  10000039-3 2023-11-12    2024-08-18      Cliente Antiguo Pasivo\n",
      "3  10000040-7 2023-02-14    2024-02-24  Cliente Antiguo Recuperado\n",
      "4  10000048-2 2023-11-22    2024-07-21      Cliente Antiguo Pasivo\n",
      "Resultado después de combinar con clasificaciones:\n",
      "       fecha            boleta  montoneto    marca            sku  cantidad  \\\n",
      "0 2025-02-02  1507824429584-01    2114.29  COLLOKY  P1JE41508AV24         1   \n",
      "1 2025-01-04  2000006954943589   15537.82  COLLOKY  7177020126I23         1   \n",
      "2 2025-02-02  1507934430144-01    5037.82  COLLOKY  P1JE19706AV25         1   \n",
      "3 2025-01-07        2691638672   15957.98  COLLOKY  5781021031V25         1   \n",
      "4 2025-01-08  1501824414091-01    2685.71  COLLOKY  C1PE021056I24         1   \n",
      "\n",
      "         area     temporada                      correo genero   canal  edad  \\\n",
      "0        ROPA    VERANO2024        lissburver@gmail.com    BOY  ONLINE  38.0   \n",
      "1     CALZADO  INVIERNO2023           21330306@meli.com    BOY  ONLINE  37.0   \n",
      "2        ROPA    VERANO2025  yuvitzabenavides@gmail.com    BOY  ONLINE  43.0   \n",
      "3     CALZADO    VERANO2025      2691638672@ecomsur.com    BOY  ONLINE  32.0   \n",
      "4  ACCESORIOS  INVIERNO2024    k.llanquileo01@gmail.com   GIRL  ONLINE  29.0   \n",
      "\n",
      "   preciolleno  edad_meses_talla_hoy  edad_ano_talla_hoy         rut  \\\n",
      "0       6990.0                  96.0                 8.0  15172914-2   \n",
      "1      36990.0                  49.0                 4.0  15362705-3   \n",
      "2      11990.0                   NaN                 NaN  13645170-7   \n",
      "3      37990.0                   NaN                 NaN  16925597-0   \n",
      "4       7990.0                  61.0                 5.0  17918455-9   \n",
      "\n",
      "   cod_tienda    clasificacion_cliente  \n",
      "0         184   Cliente Antiguo Pasivo  \n",
      "1         184  Cliente Antiguo Perdido  \n",
      "2         184  Cliente Antiguo Perdido  \n",
      "3         184   Cliente Antiguo Pasivo  \n",
      "4         184   Cliente Antiguo Activo  \n",
      "Conteo de clientes por clasificación:\n",
      "        clasificacion_cliente  total_clientes\n",
      "0      Cliente Antiguo Activo          130750\n",
      "1      Cliente Antiguo Pasivo          141903\n",
      "2     Cliente Antiguo Perdido          190701\n",
      "3  Cliente Antiguo Recuperado          154029\n",
      "4               Cliente Nuevo         2485361\n",
      "Total de RUT únicos en el mes de octubre 2024: 873383\n",
      "Conteo de clientes por clasificación:\n",
      "        clasificacion_cliente  total_clientes  porcentaje\n",
      "4               Cliente Nuevo          256000   29.311310\n",
      "2     Cliente Antiguo Perdido          190701   21.834751\n",
      "3  Cliente Antiguo Recuperado          154029   17.635905\n",
      "1      Cliente Antiguo Pasivo          141903   16.247511\n",
      "0      Cliente Antiguo Activo          130750   14.970523\n",
      "Total de RUT únicos en el mes de octubre 2024: 873383\n",
      "               rut  seg_fecha mes_fecha_min       clasificacion_cliente\n",
      "0       10000017-2 2023-07-04    2024-07-05  Cliente Antiguo Recuperado\n",
      "1       10000020-2 2021-12-16    2024-06-10     Cliente Antiguo Perdido\n",
      "2       10000039-3 2023-11-12    2024-08-18      Cliente Antiguo Pasivo\n",
      "3       10000040-7 2023-02-14    2024-02-24  Cliente Antiguo Recuperado\n",
      "4       10000048-2 2023-11-22    2024-07-21      Cliente Antiguo Pasivo\n",
      "...            ...        ...           ...                         ...\n",
      "617378   9999718-4 2023-12-23    2024-02-24      Cliente Antiguo Activo\n",
      "617379   9999753-2 2024-01-20    2024-03-07      Cliente Antiguo Activo\n",
      "617380   9999939-k 2022-02-25    2024-03-07     Cliente Antiguo Perdido\n",
      "617381   9999983-7 2023-11-25    2024-02-24      Cliente Antiguo Activo\n",
      "617382   9999990-k 2022-02-26    2024-12-23     Cliente Antiguo Perdido\n",
      "\n",
      "[617383 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "\n",
    "# Supongamos que ya tienes el DataFrame df_unificado\n",
    "# df_unificado = ... (tu DataFrame existente)\n",
    "\n",
    "# Asegurarse de que la columna 'fecha' esté en formato datetime\n",
    "df_unificado['fecha'] = pd.to_datetime(df_unificado['fecha'])\n",
    "print(\"Fecha convertida a datetime:\")\n",
    "print(df_unificado['fecha'].head())\n",
    "\n",
    "# Convertir la columna 'rut' a minúsculas\n",
    "df_unificado['rut'] = df_unificado['rut'].str.lower()\n",
    "print(\"RUTs convertidos a minúsculas:\")\n",
    "print(df_unificado['rut'].head())\n",
    "\n",
    "# Filtrar RUTs presentes en el mes base\n",
    "mes_base_inicio = '2024-02-01'\n",
    "mes_base_fin = '2025-01-31'\n",
    "mes_base_ruts = df_unificado[(df_unificado['fecha'] >= mes_base_inicio) & (df_unificado['fecha'] <= mes_base_fin)]['rut'].unique()\n",
    "print(\"RUTs en el mes base:\")\n",
    "print(mes_base_ruts[:10])  # Mostrar los primeros 10 RUTs\n",
    "\n",
    "# Filtrar las transacciones dentro del período base\n",
    "df_periodo_base = df_unificado[(df_unificado['fecha'] >= mes_base_inicio) & (df_unificado['fecha'] <= mes_base_fin)]\n",
    "\n",
    "# Obtener la primera fecha de compra dentro del período base para cada RUT\n",
    "min_fecha_por_rut = df_periodo_base.groupby('rut')['fecha'].min().reset_index()\n",
    "min_fecha_por_rut['mes_fecha_min'] = min_fecha_por_rut['fecha']\n",
    "print(\"Primera fecha de compra por RUT en el período base:\")\n",
    "print(min_fecha_por_rut.head())\n",
    "\n",
    "# Filtrar fechas anteriores a la primera fecha de compra para cada RUT de manera eficiente\n",
    "df_temp = df_unificado.merge(min_fecha_por_rut[['rut', 'mes_fecha_min']], on='rut')\n",
    "print(\"Datos después del merge con fechas mínimas:\")\n",
    "print(df_temp.head())\n",
    "\n",
    "# Filtrar filas donde la fecha es anterior a la primera fecha de compra\n",
    "df_temp = df_temp[df_temp['fecha'] < df_temp['mes_fecha_min']]\n",
    "print(\"Datos filtrados con fechas anteriores a la primera compra:\")\n",
    "print(df_temp.head())\n",
    "\n",
    "# Obtener la máxima fecha anterior a la primera fecha de compra por RUT\n",
    "df_temp = df_temp.groupby('rut').agg(seg_fecha=('fecha', 'max')).reset_index()\n",
    "print(\"Máxima fecha anterior a la primera compra por RUT:\")\n",
    "print(df_temp.head())\n",
    "\n",
    "# Clasificar los clientes usando la fecha máxima de cada rut\n",
    "def clasificar_cliente(row):\n",
    "    if pd.isna(row['seg_fecha']):\n",
    "        return None  # No clasificar aquí, lo haremos después\n",
    "    row['mes_fecha_min'] = pd.to_datetime(row['mes_fecha_min'])  # Asegurarse de que mes_fecha_min esté en formato datetime\n",
    "    if row['seg_fecha'] >= row['mes_fecha_min'] - pd.DateOffset(months=6):\n",
    "        return 'Cliente Antiguo Activo'\n",
    "    elif row['seg_fecha'] >= row['mes_fecha_min'] - pd.DateOffset(months=12):\n",
    "        return 'Cliente Antiguo Pasivo'\n",
    "    elif row['seg_fecha'] >= row['mes_fecha_min'] - pd.DateOffset(months=24):\n",
    "        return 'Cliente Antiguo Recuperado'\n",
    "    else:\n",
    "        return 'Cliente Antiguo Perdido'\n",
    "\n",
    "# Aplicar la clasificación a cada RUT\n",
    "df_temp = df_temp.merge(min_fecha_por_rut[['rut', 'mes_fecha_min']], on='rut')\n",
    "print(\"Datos después del segundo merge:\")\n",
    "print(df_temp.head())\n",
    "\n",
    "df_temp['clasificacion_cliente'] = df_temp.apply(clasificar_cliente, axis=1)\n",
    "print(\"Datos con clasificación de clientes:\")\n",
    "print(df_temp.head())\n",
    "\n",
    "# Combinar df_temp con df_unificado para agregar clasificaciones\n",
    "df_resultado = pd.merge(df_unificado, df_temp[['rut', 'clasificacion_cliente']], on='rut', how='left')\n",
    "print(\"Resultado después de combinar con clasificaciones:\")\n",
    "print(df_resultado.head())\n",
    "\n",
    "# Asignar 'Cliente Nuevo' a los RUTs que no tienen clasificación previa\n",
    "df_resultado['clasificacion_cliente'] = df_resultado['clasificacion_cliente'].fillna('Cliente Nuevo')\n",
    "\n",
    "# Contar clientes por clasificación y calcular el porcentaje\n",
    "conteo_clientes = df_resultado.groupby('clasificacion_cliente').agg(total_clientes=('rut', 'nunique')).reset_index()\n",
    "print(\"Conteo de clientes por clasificación:\")\n",
    "print(conteo_clientes)\n",
    "\n",
    "# Calcular el total de RUT únicos en el mes base\n",
    "total_ruts_octubre = len(mes_base_ruts)\n",
    "print(f\"Total de RUT únicos en el mes de octubre 2024: {total_ruts_octubre}\")\n",
    "\n",
    "# Recalcular clientes nuevos\n",
    "clientes_antiguos_total = conteo_clientes[conteo_clientes['clasificacion_cliente'] != 'Cliente Nuevo']['total_clientes'].sum()\n",
    "clientes_nuevos = total_ruts_octubre - clientes_antiguos_total\n",
    "\n",
    "# Actualizar el DataFrame de conteo\n",
    "conteo_clientes.loc[conteo_clientes['clasificacion_cliente'] == 'Cliente Nuevo', 'total_clientes'] = clientes_nuevos\n",
    "\n",
    "# Calcular el porcentaje\n",
    "conteo_clientes['porcentaje'] = (conteo_clientes['total_clientes'] / total_ruts_octubre) * 100\n",
    "conteo_clientes = conteo_clientes.sort_values(by='total_clientes', ascending=False)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(\"Conteo de clientes por clasificación:\")\n",
    "print(conteo_clientes)\n",
    "print(f\"Total de RUT únicos en el mes de octubre 2024: {total_ruts_octubre}\")\n",
    "\n",
    "# Verificación adicional\n",
    "print(df_temp[['rut', 'seg_fecha', 'mes_fecha_min', 'clasificacion_cliente']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49f9a1c2-25c6-485e-964d-b1338a55c45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de RUT únicos de clientes nuevos en noviembre 2024: 16633\n"
     ]
    }
   ],
   "source": [
    "# Filtrar solo los RUT de los clientes nuevos que están en el mes base de noviembre\n",
    "df_new_nov24 = df_resultado[(df_resultado['clasificacion_cliente'] == 'Cliente Nuevo') & (df_resultado['rut'].isin(mes_base_ruts))][['rut']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Mostrar el conteo de RUT únicos de clientes nuevos\n",
    "total_clientes_nuevos = df_new_nov24['rut'].nunique()\n",
    "print(f\"Total de RUT únicos de clientes nuevos en noviembre 2024: {total_clientes_nuevos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70aeb896-6a37-40f3-92a1-891bb0641a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de RUT únicos de clientes nuevos en noviembre 2024: 873383\n"
     ]
    }
   ],
   "source": [
    "# Filtrar solo los RUT de los clientes nuevos que están en el mes base de noviembre\n",
    "df_new_nov24 = df_resultado[(df_resultado['rut'].isin(mes_base_ruts))][['rut']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Mostrar el conteo de RUT únicos de clientes nuevos\n",
    "total_clientes_nuevos = df_new_nov24['rut'].nunique()\n",
    "print(f\"Total de RUT únicos de clientes nuevos en noviembre 2024: {total_clientes_nuevos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbd65d10-673f-466f-be61-8300a6f9afba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de filas en el DataFrame resultante del merge de df_ruts_solo_octubre con df_unificado:\n",
      "3804140\n"
     ]
    }
   ],
   "source": [
    "# Define el rango de fechas\n",
    "mes_base_inicio = '2024-02-01'\n",
    "mes_base_fin = '2025-01-31'\n",
    "\n",
    "# Filtrar df_unificado por el rango de fechas\n",
    "df_unificado_filtrado = df_unificado[(df_unificado['fecha'] >= mes_base_inicio) & (df_unificado['fecha'] <= mes_base_fin)]\n",
    "\n",
    "# Realizar el merge\n",
    "df_new_nov24_merged = df_unificado_filtrado.merge(df_new_nov24, left_on='rut', right_on='rut')\n",
    "\n",
    "# Mostrar el total de filas en el DataFrame resultante del merge\n",
    "total_filas = df_new_nov24_merged.shape[0]\n",
    "\n",
    "print(\"Total de filas en el DataFrame resultante del merge de df_ruts_solo_octubre con df_unificado:\")\n",
    "print(total_filas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d158646-f773-4ddb-987e-00b7a4a0504c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Leer un archivo Excel en un DataFrame\n",
    "ruta_excel = \"C:/Users/constanza.perez/Downloads/Lista_Precio_Colloky (2).xlsx\"\n",
    "df_precios = pd.read_excel(ruta_excel, sheet_name='Lista_Precio_Colloky')\n",
    "\n",
    "# Convertir la columna 'fecha' a formato datetime\n",
    "df_new_nov24_merged['fecha'] = pd.to_datetime(df_new_nov24_merged['fecha'])\n",
    "\n",
    "# Calcular 'monto neto final'\n",
    "df_new_nov24_merged['monto neto final'] = df_new_nov24_merged['montoneto'] * 1.19\n",
    "\n",
    "# Realizar un merge de DataFrames y renombrar columnas\n",
    "df_new_nov24_merged = df_new_nov24_merged.merge(df_precios[['Código Producto', 'Precio Un.']], how='left', left_on='sku', right_on='Código Producto')\n",
    "\n",
    "# Calcular 'Precio Lleno'\n",
    "df_new_nov24_merged['Precio Lleno'] = df_new_nov24_merged['cantidad'] * df_new_nov24_merged['Precio Un.']\n",
    "\n",
    "# Calcular 'Precio Lleno' total por boleta\n",
    "df_new_nov24_merged['Precio Lleno Boleta'] = df_new_nov24_merged.groupby('boleta')['Precio Lleno'].transform('sum')\n",
    "\n",
    "# Calcular 'monto neto final' total por boleta\n",
    "df_new_nov24_merged['Monto Neto Final Boleta'] = df_new_nov24_merged.groupby('boleta')['monto neto final'].transform('sum')\n",
    "\n",
    "# Calcular 'descuento'\n",
    "df_new_nov24_merged['descuento'] = 1 - (df_new_nov24_merged['Monto Neto Final Boleta'] / df_new_nov24_merged['Precio Lleno Boleta'])\n",
    "\n",
    "# Calcular el descuento promedio por rut\n",
    "descuento_promedio_por_rut = df_new_nov24_merged.groupby('rut')['descuento'].mean().reset_index()\n",
    "descuento_promedio_por_rut.columns = ['rut', 'Descuento Promedio']\n",
    "\n",
    "# Unir el descuento promedio al DataFrame original\n",
    "df_new_nov24_merged = df_new_nov24_merged.merge(descuento_promedio_por_rut, on='rut', how='left')\n",
    "\n",
    "# Agregar las columnas 'fecha_min' y 'fecha_max' para cada 'rut'\n",
    "df_new_nov24_merged['fecha_min'] = df_new_nov24_merged.groupby('rut')['fecha'].transform('min')\n",
    "df_new_nov24_merged['fecha_max'] = df_new_nov24_merged.groupby('rut')['fecha'].transform('max')\n",
    "\n",
    "# Asegurarse de que las fechas min y max están en formato datetime\n",
    "df_new_nov24_merged['fecha_min'] = pd.to_datetime(df_new_nov24_merged['fecha_min'])\n",
    "df_new_nov24_merged['fecha_max'] = pd.to_datetime(df_new_nov24_merged['fecha_max'])\n",
    "\n",
    "# Calcular el número de años transcurridos\n",
    "df_new_nov24_merged['years_diff'] = ((df_new_nov24_merged['fecha_max'] - df_new_nov24_merged['fecha_min']).dt.days / 365).apply(lambda x: int(x) + 1)\n",
    "\n",
    "# Agrupar por 'rut' y sumar todas las boletas únicas\n",
    "df_yearly = df_new_nov24_merged.groupby('rut')['boleta'].nunique().reset_index()\n",
    "df_yearly.columns = ['rut', 'total_boletas']\n",
    "\n",
    "# Convertir 'years_diff' a meses\n",
    "df_yearly['years_diff_months'] = df_new_nov24_merged.groupby('rut')['years_diff'].transform('max') * 12\n",
    "\n",
    "# Calcular la frecuencia mensual de compras únicas\n",
    "df_yearly['frecuencia_mensual'] = (df_yearly['total_boletas'] / df_yearly['years_diff_months'])*12\n",
    "\n",
    "# Unir la frecuencia mensual con el DataFrame original\n",
    "df_final = df_new_nov24_merged.merge(df_yearly[['rut', 'frecuencia_mensual']], on='rut', how='left')\n",
    "\n",
    "# Calcular el tiempo entre compras\n",
    "df_final = df_final.sort_values(by=['rut', 'fecha'])\n",
    "df_final['days_since_last_purchase'] = df_final.groupby('rut')['fecha'].diff().dt.days\n",
    "\n",
    "# Calcular TPC (Tiempo Promedio entre Compras)\n",
    "df_tpc = df_final[df_final['days_since_last_purchase'] > 1].groupby('rut')['days_since_last_purchase'].mean().reset_index()\n",
    "df_tpc.columns = ['rut', 'TPC']\n",
    "\n",
    "# Unir el TPC con el DataFrame original\n",
    "df_final = df_final.merge(df_tpc, on='rut', how='left')\n",
    "\n",
    "# Calcular el ticket promedio (monto neto final total por boleta agrupado por rut)\n",
    "ticket_promedio_por_rut = df_new_nov24_merged.groupby('rut')['Monto Neto Final Boleta'].mean().reset_index()\n",
    "ticket_promedio_por_rut.columns = ['rut', 'ticket prom']\n",
    "\n",
    "# Unir el ticket promedio al DataFrame final\n",
    "df_final = df_final.merge(ticket_promedio_por_rut, on='rut', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdd180e2-0887-4ee4-8bbe-ea6a7e422123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fecha</th>\n",
       "      <th>boleta</th>\n",
       "      <th>montoneto</th>\n",
       "      <th>marca</th>\n",
       "      <th>sku</th>\n",
       "      <th>cantidad</th>\n",
       "      <th>area</th>\n",
       "      <th>temporada</th>\n",
       "      <th>correo</th>\n",
       "      <th>genero</th>\n",
       "      <th>...</th>\n",
       "      <th>Monto Neto Final Boleta</th>\n",
       "      <th>descuento</th>\n",
       "      <th>Descuento Promedio</th>\n",
       "      <th>fecha_min</th>\n",
       "      <th>fecha_max</th>\n",
       "      <th>years_diff</th>\n",
       "      <th>frecuencia_mensual</th>\n",
       "      <th>days_since_last_purchase</th>\n",
       "      <th>TPC</th>\n",
       "      <th>ticket prom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-08</td>\n",
       "      <td>27096637</td>\n",
       "      <td>5038.0</td>\n",
       "      <td>COLLOKY</td>\n",
       "      <td>POJE77752AV25</td>\n",
       "      <td>1</td>\n",
       "      <td>ROPA</td>\n",
       "      <td>VERANO2025</td>\n",
       "      <td>emmaestereo@gmail.com</td>\n",
       "      <td>BOY</td>\n",
       "      <td>...</td>\n",
       "      <td>11990.44</td>\n",
       "      <td>0.499982</td>\n",
       "      <td>0.499993</td>\n",
       "      <td>2025-01-08</td>\n",
       "      <td>2025-01-08</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14656.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-08</td>\n",
       "      <td>27096636</td>\n",
       "      <td>7139.0</td>\n",
       "      <td>COLLOKY</td>\n",
       "      <td>PTPO11032AV25</td>\n",
       "      <td>1</td>\n",
       "      <td>ROPA</td>\n",
       "      <td>VERANO2025</td>\n",
       "      <td>emmaestereo@gmail.com</td>\n",
       "      <td>BOY</td>\n",
       "      <td>...</td>\n",
       "      <td>16989.63</td>\n",
       "      <td>0.500011</td>\n",
       "      <td>0.499993</td>\n",
       "      <td>2025-01-08</td>\n",
       "      <td>2025-01-08</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14656.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-08</td>\n",
       "      <td>27096637</td>\n",
       "      <td>5038.0</td>\n",
       "      <td>COLLOKY</td>\n",
       "      <td>POJE8166XXV25</td>\n",
       "      <td>1</td>\n",
       "      <td>ROPA</td>\n",
       "      <td>VERANO2025</td>\n",
       "      <td>emmaestereo@gmail.com</td>\n",
       "      <td>BOY</td>\n",
       "      <td>...</td>\n",
       "      <td>11990.44</td>\n",
       "      <td>0.499982</td>\n",
       "      <td>0.499993</td>\n",
       "      <td>2025-01-08</td>\n",
       "      <td>2025-01-08</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14656.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-01-08</td>\n",
       "      <td>27096636</td>\n",
       "      <td>7138.0</td>\n",
       "      <td>COLLOKY</td>\n",
       "      <td>PLPO39972AV25</td>\n",
       "      <td>1</td>\n",
       "      <td>ROPA</td>\n",
       "      <td>VERANO2025</td>\n",
       "      <td>emmaestereo@gmail.com</td>\n",
       "      <td>BOY</td>\n",
       "      <td>...</td>\n",
       "      <td>16989.63</td>\n",
       "      <td>0.500011</td>\n",
       "      <td>0.499993</td>\n",
       "      <td>2025-01-08</td>\n",
       "      <td>2025-01-08</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14656.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-01-08</td>\n",
       "      <td>27096635</td>\n",
       "      <td>6299.0</td>\n",
       "      <td>COLLOKY</td>\n",
       "      <td>PTPO13572AV25</td>\n",
       "      <td>1</td>\n",
       "      <td>ROPA</td>\n",
       "      <td>VERANO2025</td>\n",
       "      <td>emmaestereo@gmail.com</td>\n",
       "      <td>BOY</td>\n",
       "      <td>...</td>\n",
       "      <td>14990.43</td>\n",
       "      <td>0.499986</td>\n",
       "      <td>0.499993</td>\n",
       "      <td>2025-01-08</td>\n",
       "      <td>2025-01-08</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14656.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fecha    boleta  montoneto    marca            sku  cantidad  area  \\\n",
       "0 2025-01-08  27096637     5038.0  COLLOKY  POJE77752AV25         1  ROPA   \n",
       "1 2025-01-08  27096636     7139.0  COLLOKY  PTPO11032AV25         1  ROPA   \n",
       "2 2025-01-08  27096637     5038.0  COLLOKY  POJE8166XXV25         1  ROPA   \n",
       "3 2025-01-08  27096636     7138.0  COLLOKY  PLPO39972AV25         1  ROPA   \n",
       "4 2025-01-08  27096635     6299.0  COLLOKY  PTPO13572AV25         1  ROPA   \n",
       "\n",
       "    temporada                 correo genero  ... Monto Neto Final Boleta  \\\n",
       "0  VERANO2025  emmaestereo@gmail.com    BOY  ...                11990.44   \n",
       "1  VERANO2025  emmaestereo@gmail.com    BOY  ...                16989.63   \n",
       "2  VERANO2025  emmaestereo@gmail.com    BOY  ...                11990.44   \n",
       "3  VERANO2025  emmaestereo@gmail.com    BOY  ...                16989.63   \n",
       "4  VERANO2025  emmaestereo@gmail.com    BOY  ...                14990.43   \n",
       "\n",
       "   descuento  Descuento Promedio  fecha_min  fecha_max years_diff  \\\n",
       "0   0.499982            0.499993 2025-01-08 2025-01-08          1   \n",
       "1   0.500011            0.499993 2025-01-08 2025-01-08          1   \n",
       "2   0.499982            0.499993 2025-01-08 2025-01-08          1   \n",
       "3   0.500011            0.499993 2025-01-08 2025-01-08          1   \n",
       "4   0.499986            0.499993 2025-01-08 2025-01-08          1   \n",
       "\n",
       "   frecuencia_mensual  days_since_last_purchase TPC   ticket prom  \n",
       "0                 3.0                       NaN NaN  14656.833333  \n",
       "1                 3.0                       0.0 NaN  14656.833333  \n",
       "2                 3.0                       0.0 NaN  14656.833333  \n",
       "3                 3.0                       0.0 NaN  14656.833333  \n",
       "4                 3.0                       0.0 NaN  14656.833333  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Establecer 'descuento' como 0 si es menor que 0\n",
    "df_final.loc[df_final['descuento'] < 0, 'descuento'] = 0\n",
    "\n",
    "# Imprimir el DataFrame final\n",
    "(df_final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14f73e28-ab17-4dcb-949e-93a08b95fcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       fecha    boleta  montoneto    marca            sku  cantidad  \\\n",
      "0 2025-01-08  27096637     5038.0  COLLOKY  POJE77752AV25         1   \n",
      "1 2024-07-05  26196122    20160.0  COLLOKY  5406023029I23         1   \n",
      "2 2024-06-10  26079512    21672.0  COLLOKY  4420023025I23         1   \n",
      "3 2024-08-18  26385594    12601.0  COLLOKY  5798021032V25         1   \n",
      "4 2024-02-24  25513408     7554.0  COLLOKY  C2CSU55078I24         1   \n",
      "\n",
      "         area     temporada                       correo      genero  ...  \\\n",
      "0        ROPA    VERANO2025        emmaestereo@gmail.com         BOY  ...   \n",
      "1     CALZADO  INVIERNO2023          fernandav@gmail.com        GIRL  ...   \n",
      "2     CALZADO  INVIERNO2023  miriiammunozulloa@gmail.com        GIRL  ...   \n",
      "3     CALZADO    VERANO2025             arodri@gmail.com        GIRL  ...   \n",
      "4  ACCESORIOS  INVIERNO2024                          NaN  Sin Genero  ...   \n",
      "\n",
      "   fecha_min  fecha_max  years_diff  frecuencia_mensual  \\\n",
      "0 2025-01-08 2025-01-08           1                 3.0   \n",
      "1 2024-07-05 2024-07-05           1                 2.0   \n",
      "2 2024-06-10 2024-06-10           1                 1.0   \n",
      "3 2024-08-18 2024-09-27           1                 4.0   \n",
      "4 2024-02-24 2024-08-27           1                 2.0   \n",
      "\n",
      "   days_since_last_purchase    TPC   ticket prom  area_categorizada  \\\n",
      "0                       NaN    NaN  14656.833333          SOLO ROPA   \n",
      "1                       NaN    NaN  41650.000000              MIXTO   \n",
      "2                       NaN    NaN  25789.680000       SOLO CALZADO   \n",
      "3                       NaN   19.5  37544.053750              MIXTO   \n",
      "4                       NaN  185.0  39774.084000              MIXTO   \n",
      "\n",
      "  genero_categorizado  canal_categorizado  \n",
      "0                 BOY             OFFLINE  \n",
      "1                GIRL             OFFLINE  \n",
      "2                GIRL             OFFLINE  \n",
      "3               MIXTO             OFFLINE  \n",
      "4               MIXTO             OFFLINE  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Función de categorización para la columna 'area'\n",
    "def categorize_area(column_values):\n",
    "    unique_values = column_values.unique()\n",
    "    if len(unique_values) == 1:\n",
    "        if 'CALZADO' in unique_values:\n",
    "            return 'SOLO CALZADO'\n",
    "        if 'ACCESORIOS' in unique_values:\n",
    "            return 'SOLO ACCESORIO'\n",
    "        if 'ROPA' in unique_values:\n",
    "            return 'SOLO ROPA'\n",
    "    if all(item in unique_values for item in ['CALZADO', 'ACCESORIOS', 'ROPA']):\n",
    "        return 'MIXTO'\n",
    "    elif 'CALZADO' in unique_values and 'ACCESORIOS' in unique_values:\n",
    "        return 'MIXTO'\n",
    "    elif 'CALZADO' in unique_values and 'ROPA' in unique_values:\n",
    "        return 'MIXTO'\n",
    "    elif 'ACCESORIOS' in unique_values and 'ROPA' in unique_values:\n",
    "        return 'MIXTO'\n",
    "    else:\n",
    "        return 'MIXTO'\n",
    "\n",
    "# Función de categorización para las columnas 'genero' y 'canal'\n",
    "def categorize_other(column_values):\n",
    "    unique_values = column_values.unique()\n",
    "    if 'ACCESORIOS' in unique_values:\n",
    "        return 'ROPA'\n",
    "    if len(unique_values) == 1:\n",
    "        return unique_values[0]\n",
    "    else:\n",
    "        return 'MIXTO'\n",
    "\n",
    "# Aplicar las transformaciones sin perder columnas\n",
    "df_final['area_categorizada'] = df_final.groupby('rut')['area'].transform(categorize_area)\n",
    "df_final['genero_categorizado'] = df_final.groupby('rut')['genero'].transform(categorize_other)\n",
    "df_final['canal_categorizado'] = df_final.groupby('rut')['canal'].transform(categorize_other)\n",
    "\n",
    "# Eliminar duplicados para obtener 'rut' único\n",
    "df_result = df_final.drop_duplicates(subset='rut').reset_index(drop=True)\n",
    "\n",
    "# Imprimir el DataFrame final agrupado y categorizado\n",
    "print(df_result.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79a5b112-faec-4fe5-858d-d5cb5fa53948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>area_categorizada</th>\n",
       "      <th>genero_categorizado</th>\n",
       "      <th>canal_categorizado</th>\n",
       "      <th>frecuencia_mensual_rango</th>\n",
       "      <th>ticket_promedio_rango</th>\n",
       "      <th>edad_rango</th>\n",
       "      <th>descuento_rango</th>\n",
       "      <th>tpc_rango</th>\n",
       "      <th>edad_ano_talla_hoy_rango</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cantidad</th>\n",
       "      <td>873383.0</td>\n",
       "      <td>1.02066</td>\n",
       "      <td>0.170714</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edad</th>\n",
       "      <td>854168.0</td>\n",
       "      <td>35.941954</td>\n",
       "      <td>14.463719</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edad_ano_talla_hoy</th>\n",
       "      <td>598572.0</td>\n",
       "      <td>6.020781</td>\n",
       "      <td>3.514083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticket prom</th>\n",
       "      <td>873383.0</td>\n",
       "      <td>33416.357772</td>\n",
       "      <td>27019.3309</td>\n",
       "      <td>-22711.621882</td>\n",
       "      <td>19589.78</td>\n",
       "      <td>28084.8092</td>\n",
       "      <td>39989.95</td>\n",
       "      <td>2800443.66</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frecuencia_mensual</th>\n",
       "      <td>873383.0</td>\n",
       "      <td>1.917771</td>\n",
       "      <td>5.593297</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4869.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPC</th>\n",
       "      <td>306818.0</td>\n",
       "      <td>89.312258</td>\n",
       "      <td>73.055215</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>365.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>descuento</th>\n",
       "      <td>873383.0</td>\n",
       "      <td>0.28243</td>\n",
       "      <td>0.219897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.300104</td>\n",
       "      <td>0.464785</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>MIXTO: 42%, SOLO CALZADO: 36%, SOLO ROPA: 14%, SOLO ACCESORIO: 7%</td>\n",
       "      <td>GIRL: 38%, BOY: 29%, MIXTO: 29%, Sin Genero: 4%, WOMAN: 0%, Niño: 0%, Unisex: 0%, Niña: 0%, UNISEX: 0%</td>\n",
       "      <td>OFFLINE: 81%, ONLINE: 10%, MIXTO: 9%</td>\n",
       "      <td>1: 62%, 2: 19%, 3: 8%, 4: 4%, 5: 2%, 6: 1%, 7: 1%, Mayor a 10: 1%, 8: 1%, 9: 0%, 10: 0%, 0: 0%</td>\n",
       "      <td>15001-30000: 41%, 30001-45000: 26%, 0-15000: 14%, 45001-60000: 10%, Mayor a 60000: 9%</td>\n",
       "      <td>31-40: 31%, 19-30: 29%, 41-50: 16%, 51-60: 8%, Mayor a 60: 6%, 0-18: 6%</td>\n",
       "      <td>0%-20%: 35%, Mayor a 40% - 60%: 29%, Mayor a 20% - 40%: 27%, Mayor a 60%: 9%</td>\n",
       "      <td>Mayor a 1: 100%, 0-1: 0%</td>\n",
       "      <td>3: 8%, 6: 7%, 0: 7%, 2: 6%, 4: 6%, 1: 6%, 5: 5%, 9: 5%, 11: 4%, 8: 4%, 10: 4%, 7: 4%, 12: 1%, 16: 0%, 13: 0%, 15: 0%, 14: 0%, 17: 0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Redondear los valores de frecuencia_mensual\n",
    "df_result['frecuencia_mensual_redondeada'] = df_result['frecuencia_mensual'].apply(lambda x: round(x))\n",
    "\n",
    "# Asignar rangos directamente según los valores redondeados de frecuencia_mensual\n",
    "df_result['frecuencia_mensual_rango'] = df_result['frecuencia_mensual_redondeada'].apply(lambda x: str(x) if x <= 10 else 'Mayor a 10')\n",
    "\n",
    "\n",
    "# Crear rangos para la variable TICKET PROMEDIO\n",
    "df_result['ticket_promedio_rango'] = pd.cut(df_result['ticket prom'], bins=[0, 15000, 30000, 45000, 60000, float('inf')],\n",
    "                                            labels=['0-15000', '15001-30000', '30001-45000', '45001-60000', 'Mayor a 60000'])\n",
    "\n",
    "# Crear rangos para la variable edad, excluyendo valores nulos\n",
    "df_result['edad_rango'] = pd.cut(df_result['edad'].dropna(), bins=[0, 18, 30, 40, 50, 60, float('inf')],\n",
    "                                 labels=['0-18', '19-30', '31-40', '41-50', '51-60', 'Mayor a 60'])\n",
    "\n",
    "# Ajustar rangos para la variable descuento según tu requerimiento\n",
    "df_result['descuento_rango'] = pd.cut(df_result['descuento'], bins=[-0.01, 0.20, 0.40, 0.60, float('inf')],\n",
    "                                      labels=['0%-20%', 'Mayor a 20% - 40%', 'Mayor a 40% - 60%', 'Mayor a 60%'])\n",
    "\n",
    "# Crear rangos para la variable TPC\n",
    "df_result['tpc_rango'] = pd.cut(df_result['TPC'], bins=[0, 1, float('inf')],\n",
    "                                labels=['0-1', 'Mayor a 1'])\n",
    "\n",
    "# Crear rangos para la variable edad_ano_talla_hoy, excluyendo valores nulos\n",
    "max_edad_ano_talla_hoy = int(df_result['edad_ano_talla_hoy'].max())  # Convertir a entero\n",
    "df_result['edad_ano_talla_hoy_rango'] = pd.cut(df_result['edad_ano_talla_hoy'].dropna(), \n",
    "                                               bins=range(0, max_edad_ano_talla_hoy + 2),\n",
    "                                               labels=[str(i) for i in range(0, max_edad_ano_talla_hoy + 1)])\n",
    "\n",
    "# Función para formatear los porcentajes sin decimales ni puntos\n",
    "def format_percentage_without_decimals(column_values):\n",
    "    counts = column_values.value_counts()\n",
    "    return ', '.join([f\"{index}: {int(round((count / len(column_values)) * 100))}%\" for index, count in counts.items()])\n",
    "\n",
    "# Calcular los porcentajes de las variables categóricas, excluyendo valores nulos, NaN o vacíos\n",
    "porcentajes_area = format_percentage_without_decimals(df_result['area_categorizada'].dropna())\n",
    "porcentajes_genero = format_percentage_without_decimals(df_result['genero_categorizado'].dropna())\n",
    "porcentajes_canal = format_percentage_without_decimals(df_result['canal_categorizado'].dropna())\n",
    "porcentajes_frecuencia_mensual = format_percentage_without_decimals(df_result['frecuencia_mensual_rango'].dropna())\n",
    "porcentajes_ticket_promedio = format_percentage_without_decimals(df_result['ticket_promedio_rango'].dropna())\n",
    "porcentajes_edad = format_percentage_without_decimals(df_result['edad_rango'])\n",
    "porcentajes_descuento = format_percentage_without_decimals(df_result['descuento_rango'].dropna())\n",
    "porcentajes_tpc = format_percentage_without_decimals(df_result['tpc_rango'].dropna())\n",
    "porcentajes_edad_ano_talla_hoy = format_percentage_without_decimals(df_result['edad_ano_talla_hoy_rango'])\n",
    "\n",
    "# Calcular las estadísticas descriptivas de las variables numéricas seleccionadas\n",
    "estadisticas_numericas = df_result[['cantidad', 'edad', 'edad_ano_talla_hoy', 'ticket prom', 'frecuencia_mensual', 'TPC', 'descuento']].describe().transpose()\n",
    "\n",
    "# Crear un DataFrame con las distribuciones y estadísticas\n",
    "distribuciones = pd.DataFrame({\n",
    "    'area_categorizada': [porcentajes_area],\n",
    "    'genero_categorizado': [porcentajes_genero],\n",
    "    'canal_categorizado': [porcentajes_canal],\n",
    "    'frecuencia_mensual_rango': [porcentajes_frecuencia_mensual],\n",
    "    'ticket_promedio_rango': [porcentajes_ticket_promedio],\n",
    "    'edad_rango': [porcentajes_edad],\n",
    "    'descuento_rango': [porcentajes_descuento],\n",
    "    'tpc_rango': [porcentajes_tpc],\n",
    "    'edad_ano_talla_hoy_rango': [porcentajes_edad_ano_talla_hoy]\n",
    "})\n",
    "\n",
    "# Unir los DataFrames de distribuciones y estadísticas\n",
    "resultados_generales = pd.concat([estadisticas_numericas, distribuciones], axis=1).fillna('')\n",
    "\n",
    "# Convertir el DataFrame a HTML para mejor visualización\n",
    "display(HTML(resultados_generales.to_html(escape=False)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de4680cc-ddf5-46a9-bbd0-ae56c406718b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 85\u001b[0m\n\u001b[0;32m     82\u001b[0m ddf_result \u001b[38;5;241m=\u001b[39m ddf_result\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrut\u001b[39m\u001b[38;5;124m'\u001b[39m, group_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mapply(apply_get_top_80_percent, meta\u001b[38;5;241m=\u001b[39mddf_result)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# Asegurarse de que no haya NaN antes de calcular el máximo\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m max_edad_ano_talla_hoy \u001b[38;5;241m=\u001b[39m ddf_result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medad_ano_talla_hoy\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdropna()\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[0;32m     86\u001b[0m max_edad_ano_talla_hoy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(max_edad_ano_talla_hoy) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pd\u001b[38;5;241m.\u001b[39misna(max_edad_ano_talla_hoy) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# Crear rangos para la variable edad_ano_talla_hoy sin usar cut\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\dask_expr\\_collection.py:475\u001b[0m, in \u001b[0;36mFrameBase.compute\u001b[1;34m(self, fuse, **kwargs)\u001b[0m\n\u001b[0;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, Scalar):\n\u001b[0;32m    474\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mrepartition(npartitions\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 475\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39moptimize(fuse\u001b[38;5;241m=\u001b[39mfuse)\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DaskMethodsMixin\u001b[38;5;241m.\u001b[39mcompute(out, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\dask_expr\\_collection.py:590\u001b[0m, in \u001b[0;36mFrameBase.optimize\u001b[1;34m(self, fuse)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\u001b[38;5;28mself\u001b[39m, fuse: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    573\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimizes the DataFrame.\u001b[39;00m\n\u001b[0;32m    574\u001b[0m \n\u001b[0;32m    575\u001b[0m \u001b[38;5;124;03m    Runs the optimizer with all steps over the DataFrame and wraps the result in a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;124;03m        The optimized Dask Dataframe\u001b[39;00m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 590\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_collection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpr\u001b[38;5;241m.\u001b[39moptimize(fuse\u001b[38;5;241m=\u001b[39mfuse))\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\dask_expr\\_expr.py:94\u001b[0m, in \u001b[0;36mExpr.optimize\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m optimize(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\dask_expr\\_expr.py:3028\u001b[0m, in \u001b[0;36moptimize\u001b[1;34m(expr, fuse)\u001b[0m\n\u001b[0;32m   3007\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"High level query optimization\u001b[39;00m\n\u001b[0;32m   3008\u001b[0m \n\u001b[0;32m   3009\u001b[0m \u001b[38;5;124;03mThis leverages three optimization passes:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3024\u001b[0m \u001b[38;5;124;03moptimize_blockwise_fusion\u001b[39;00m\n\u001b[0;32m   3025\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3026\u001b[0m stage: core\u001b[38;5;241m.\u001b[39mOptimizerStage \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfused\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fuse \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimplified-physical\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 3028\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m optimize_until(expr, stage)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\dask_expr\\_expr.py:2999\u001b[0m, in \u001b[0;36moptimize_until\u001b[1;34m(expr, stage)\u001b[0m\n\u001b[0;32m   2996\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m expr\n\u001b[0;32m   2998\u001b[0m \u001b[38;5;66;03m# Final graph-specific optimizations\u001b[39;00m\n\u001b[1;32m-> 2999\u001b[0m expr \u001b[38;5;241m=\u001b[39m optimize_blockwise_fusion(expr)\n\u001b[0;32m   3000\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stage \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfused\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   3001\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m expr\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\dask_expr\\_expr.py:3197\u001b[0m, in \u001b[0;36moptimize_blockwise_fusion\u001b[1;34m(expr)\u001b[0m\n\u001b[0;32m   3195\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m   3196\u001b[0m     original_name \u001b[38;5;241m=\u001b[39m expr\u001b[38;5;241m.\u001b[39m_name\n\u001b[1;32m-> 3197\u001b[0m     expr, done \u001b[38;5;241m=\u001b[39m _fusion_pass(expr)\n\u001b[0;32m   3198\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m done \u001b[38;5;129;01mor\u001b[39;00m expr\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m==\u001b[39m original_name:\n\u001b[0;32m   3199\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\dask_expr\\_expr.py:3162\u001b[0m, in \u001b[0;36moptimize_blockwise_fusion.<locals>._fusion_pass\u001b[1;34m(expr)\u001b[0m\n\u001b[0;32m   3159\u001b[0m stack_names \u001b[38;5;241m=\u001b[39m {s\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m stack}\n\u001b[0;32m   3160\u001b[0m group_names \u001b[38;5;241m=\u001b[39m {g\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m group}\n\u001b[0;32m   3161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m-> 3162\u001b[0m     dep\u001b[38;5;241m.\u001b[39mnpartitions \u001b[38;5;241m==\u001b[39m root\u001b[38;5;241m.\u001b[39mnpartitions \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mnext\u001b[39m\u001b[38;5;241m.\u001b[39m_broadcast_dep(dep)\n\u001b[0;32m   3163\u001b[0m ) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (dependents[dep\u001b[38;5;241m.\u001b[39m_name] \u001b[38;5;241m-\u001b[39m stack_names \u001b[38;5;241m-\u001b[39m group_names):\n\u001b[0;32m   3164\u001b[0m     \u001b[38;5;66;03m# All of deps dependents are contained\u001b[39;00m\n\u001b[0;32m   3165\u001b[0m     \u001b[38;5;66;03m# in the local group (or the local stack\u001b[39;00m\n\u001b[0;32m   3166\u001b[0m     \u001b[38;5;66;03m# of expr nodes that we know we will be\u001b[39;00m\n\u001b[0;32m   3167\u001b[0m     \u001b[38;5;66;03m# adding to the local group).\u001b[39;00m\n\u001b[0;32m   3168\u001b[0m     \u001b[38;5;66;03m# All nodes must also have the same number\u001b[39;00m\n\u001b[0;32m   3169\u001b[0m     \u001b[38;5;66;03m# of partitions, since broadcasting within\u001b[39;00m\n\u001b[0;32m   3170\u001b[0m     \u001b[38;5;66;03m# a group is not allowed.\u001b[39;00m\n\u001b[0;32m   3171\u001b[0m     stack\u001b[38;5;241m.\u001b[39mappend(dep)\n\u001b[0;32m   3172\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dependencies[dep\u001b[38;5;241m.\u001b[39m_name] \u001b[38;5;129;01mand\u001b[39;00m dep\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m   3173\u001b[0m     r\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m roots\n\u001b[0;32m   3174\u001b[0m ]:\n\u001b[0;32m   3175\u001b[0m     \u001b[38;5;66;03m# Couldn't fuse dep, but we may be able to\u001b[39;00m\n\u001b[0;32m   3176\u001b[0m     \u001b[38;5;66;03m# use it as a new root on the next pass\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\dask_expr\\_expr.py:398\u001b[0m, in \u001b[0;36mExpr.npartitions\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moperands[idx]\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdivisions) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\functools.py:995\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[1;34m(self, instance, owner)\u001b[0m\n\u001b[0;32m    993\u001b[0m val \u001b[38;5;241m=\u001b[39m cache\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname, _NOT_FOUND)\n\u001b[0;32m    994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m _NOT_FOUND:\n\u001b[1;32m--> 995\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(instance)\n\u001b[0;32m    996\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    997\u001b[0m         cache[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname] \u001b[38;5;241m=\u001b[39m val\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\dask_expr\\_expr.py:382\u001b[0m, in \u001b[0;36mExpr.divisions\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mcached_property\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdivisions\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 382\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_divisions())\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\dask_expr\\_expr.py:529\u001b[0m, in \u001b[0;36mBlockwise._divisions\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    527\u001b[0m dependencies \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdependencies()\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m dependencies:\n\u001b[1;32m--> 529\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_broadcast_dep(arg):\n\u001b[0;32m    530\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m arg\u001b[38;5;241m.\u001b[39mdivisions \u001b[38;5;241m==\u001b[39m dependencies[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdivisions\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dependencies[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdivisions\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\dask_expr\\_expr.py:520\u001b[0m, in \u001b[0;36mBlockwise._broadcast_dep\u001b[1;34m(self, dep)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_broadcast_dep\u001b[39m(\u001b[38;5;28mself\u001b[39m, dep: Expr):\n\u001b[0;32m    518\u001b[0m     \u001b[38;5;66;03m# Checks if a dependency should be broadcasted to\u001b[39;00m\n\u001b[0;32m    519\u001b[0m     \u001b[38;5;66;03m# all partitions of this `Blockwise` operation\u001b[39;00m\n\u001b[1;32m--> 520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dep\u001b[38;5;241m.\u001b[39mnpartitions \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m dep\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\dask_expr\\_expr.py:398\u001b[0m, in \u001b[0;36mExpr.npartitions\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moperands[idx]\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdivisions) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\functools.py:995\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[1;34m(self, instance, owner)\u001b[0m\n\u001b[0;32m    993\u001b[0m val \u001b[38;5;241m=\u001b[39m cache\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname, _NOT_FOUND)\n\u001b[0;32m    994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m _NOT_FOUND:\n\u001b[1;32m--> 995\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(instance)\n\u001b[0;32m    996\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    997\u001b[0m         cache[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname] \u001b[38;5;241m=\u001b[39m val\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\dask_expr\\_expr.py:382\u001b[0m, in \u001b[0;36mExpr.divisions\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mcached_property\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdivisions\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 382\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_divisions())\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\dask_expr\\_expr.py:2067\u001b[0m, in \u001b[0;36mProjection._divisions\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2065\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   2066\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 2067\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_divisions()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\dask_expr\\_expr.py:529\u001b[0m, in \u001b[0;36mBlockwise._divisions\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    527\u001b[0m dependencies \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdependencies()\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m dependencies:\n\u001b[1;32m--> 529\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_broadcast_dep(arg):\n\u001b[0;32m    530\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m arg\u001b[38;5;241m.\u001b[39mdivisions \u001b[38;5;241m==\u001b[39m dependencies[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdivisions\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dependencies[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdivisions\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\dask_expr\\_expr.py:520\u001b[0m, in \u001b[0;36mBlockwise._broadcast_dep\u001b[1;34m(self, dep)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_broadcast_dep\u001b[39m(\u001b[38;5;28mself\u001b[39m, dep: Expr):\n\u001b[0;32m    518\u001b[0m     \u001b[38;5;66;03m# Checks if a dependency should be broadcasted to\u001b[39;00m\n\u001b[0;32m    519\u001b[0m     \u001b[38;5;66;03m# all partitions of this `Blockwise` operation\u001b[39;00m\n\u001b[1;32m--> 520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dep\u001b[38;5;241m.\u001b[39mnpartitions \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m dep\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\dask_expr\\_expr.py:398\u001b[0m, in \u001b[0;36mExpr.npartitions\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moperands[idx]\n\u001b[0;32m    397\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdivisions) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\functools.py:995\u001b[0m, in \u001b[0;36mcached_property.__get__\u001b[1;34m(self, instance, owner)\u001b[0m\n\u001b[0;32m    993\u001b[0m val \u001b[38;5;241m=\u001b[39m cache\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname, _NOT_FOUND)\n\u001b[0;32m    994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mis\u001b[39;00m _NOT_FOUND:\n\u001b[1;32m--> 995\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(instance)\n\u001b[0;32m    996\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    997\u001b[0m         cache[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrname] \u001b[38;5;241m=\u001b[39m val\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\dask_expr\\_expr.py:382\u001b[0m, in \u001b[0;36mExpr.divisions\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mcached_property\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdivisions\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 382\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_divisions())\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\dask_expr\\_expr.py:530\u001b[0m, in \u001b[0;36mBlockwise._divisions\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m dependencies:\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_broadcast_dep(arg):\n\u001b[1;32m--> 530\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m arg\u001b[38;5;241m.\u001b[39mdivisions \u001b[38;5;241m==\u001b[39m dependencies[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdivisions\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dependencies[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdivisions\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Convertir el DataFrame de pandas a Dask\n",
    "ddf_result = dd.from_pandas(df_result.reset_index(drop=True), npartitions=4)\n",
    "\n",
    "# Redondear los valores de frecuencia_mensual\n",
    "ddf_result['frecuencia_mensual_redondeada'] = ddf_result['frecuencia_mensual'].round()\n",
    "\n",
    "# Asignar rangos directamente según los valores redondeados de frecuencia_mensual\n",
    "ddf_result['frecuencia_mensual_rango'] = ddf_result['frecuencia_mensual_redondeada'].apply(lambda x: str(x) if x <= 10 else 'Mayor a 10', meta=('frecuencia_mensual_rango', 'str'))\n",
    "\n",
    "# Mapear rangos para la variable TICKET PROMEDIO\n",
    "def map_ticket_promedio(x):\n",
    "    if x <= 15000:\n",
    "        return '0-15000'\n",
    "    elif x <= 30000:\n",
    "        return '15001-30000'\n",
    "    elif x <= 45000:\n",
    "        return '30001-45000'\n",
    "    elif x <= 60000:\n",
    "        return '45001-60000'\n",
    "    else:\n",
    "        return 'Mayor a 60000'\n",
    "\n",
    "ddf_result['ticket_promedio_rango'] = ddf_result['ticket prom'].map(map_ticket_promedio, meta=('ticket_promedio_rango', 'str'))\n",
    "\n",
    "# Mapear rangos para la variable edad\n",
    "def map_edad(x):\n",
    "    if x <= 18:\n",
    "        return '0-18'\n",
    "    elif x <= 30:\n",
    "        return '19-30'\n",
    "    elif x <= 40:\n",
    "        return '31-40'\n",
    "    elif x <= 50:\n",
    "        return '41-50'\n",
    "    elif x <= 60:\n",
    "        return '51-60'\n",
    "    else:\n",
    "        return 'Mayor a 60'\n",
    "\n",
    "ddf_result['edad_rango'] = ddf_result['edad'].map(map_edad, meta=('edad_rango', 'str'))\n",
    "\n",
    "# Mapear rangos para la variable descuento\n",
    "def map_descuento(x):\n",
    "    if x <= 0.20:\n",
    "        return '0%-20%'\n",
    "    elif x <= 0.40:\n",
    "        return 'Mayor a 20% - 40%'\n",
    "    elif x <= 0.60:\n",
    "        return 'Mayor a 40% - 60%'\n",
    "    else:\n",
    "        return 'Mayor a 60%'\n",
    "\n",
    "ddf_result['descuento_rango'] = ddf_result['descuento'].map(map_descuento, meta=('descuento_rango', 'str'))\n",
    "\n",
    "# Mapear rangos para la variable TPC\n",
    "def map_tpc(x):\n",
    "    if x <= 1:\n",
    "        return '0-1'\n",
    "    else:\n",
    "        return 'Mayor a 1'\n",
    "\n",
    "ddf_result['tpc_rango'] = ddf_result['TPC'].map(map_tpc, meta=('tpc_rango', 'str'))\n",
    "\n",
    "# Eliminar valores NaN en 'edad_ano_talla_hoy' antes de agrupar y aplicar la función\n",
    "ddf_result = ddf_result.dropna(subset=['edad_ano_talla_hoy'])\n",
    "\n",
    "# Optimizar el cálculo de las edades según el 80% de las boletas\n",
    "def get_top_80_percent(df_group):\n",
    "    counts = df_group['edad_ano_talla_hoy'].value_counts(normalize=True).cumsum()\n",
    "    valid_ages = counts[counts <= 0.8].index.tolist()\n",
    "    return df_group[df_group['edad_ano_talla_hoy'].isin(valid_ages)]\n",
    "\n",
    "# Aplicar la función a cada grupo de 'rut', asegurando que 'rut' no sea un índice\n",
    "def apply_get_top_80_percent(group):\n",
    "    group = group.reset_index(drop=True)\n",
    "    return get_top_80_percent(group)\n",
    "\n",
    "ddf_result = ddf_result.groupby('rut', group_keys=False).apply(apply_get_top_80_percent, meta=ddf_result)\n",
    "\n",
    "# Asegurarse de que no haya NaN antes de calcular el máximo\n",
    "max_edad_ano_talla_hoy = ddf_result['edad_ano_talla_hoy'].dropna().max().compute()\n",
    "max_edad_ano_talla_hoy = int(max_edad_ano_talla_hoy) if not pd.isna(max_edad_ano_talla_hoy) else 0\n",
    "\n",
    "# Crear rangos para la variable edad_ano_talla_hoy sin usar cut\n",
    "def map_edad_ano_talla_hoy(x, max_val):\n",
    "    if pd.isna(x):\n",
    "        return 'NaN'\n",
    "    for i in range(max_val + 1):\n",
    "        if x == i:\n",
    "            return str(i)\n",
    "    return 'Mayor a ' + str(max_val)\n",
    "\n",
    "ddf_result['edad_ano_talla_hoy_rango'] = ddf_result['edad_ano_talla_hoy'].map(lambda x: map_edad_ano_talla_hoy(x, max_edad_ano_talla_hoy), meta=('edad_ano_talla_hoy_rango', 'str'))\n",
    "\n",
    "# Función para formatear los porcentajes sin decimales ni puntos\n",
    "def format_percentage_without_decimals(column):\n",
    "    counts = column.value_counts().compute()\n",
    "    total = counts.sum()\n",
    "    return ', '.join([f\"{index}: {int(round((count / total) * 100))}%\" for index, count in counts.items()])\n",
    "\n",
    "# Calcular los porcentajes de las variables categóricas, excluyendo valores nulos, NaN o vacíos\n",
    "def calculate_percentages(column):\n",
    "    return format_percentage_without_decimals(ddf_result[column].dropna())\n",
    "\n",
    "# Variables categóricas a procesar\n",
    "categorical_vars = [\n",
    "    'area_categorizada', 'genero_categorizado', 'canal_categorizado', \n",
    "    'frecuencia_mensual_rango', 'ticket_promedio_rango', 'edad_rango', \n",
    "    'descuento_rango', 'tpc_rango', 'edad_ano_talla_hoy_rango'\n",
    "]\n",
    "\n",
    "# Calcular porcentajes de todas las variables categóricas\n",
    "porcentajes = {var: calculate_percentages(var) for var in categorical_vars}\n",
    "\n",
    "# Convertir resultados de porcentajes a un DataFrame\n",
    "porcentajes_df = pd.DataFrame(porcentajes, index=[0])\n",
    "\n",
    "# Calcular las estadísticas descriptivas de las variables numéricas seleccionadas\n",
    "estadisticas_numericas = ddf_result[['cantidad', 'edad', 'edad_ano_talla_hoy', 'ticket prom', 'frecuencia_mensual', 'TPC', 'descuento']].describe().compute().transpose()\n",
    "\n",
    "# Unir los DataFrames de distribuciones y estadísticas\n",
    "resultados_generales = pd.concat([estadisticas_numericas, porcentajes_df], axis=1).fillna('')\n",
    "\n",
    "# Convertir el DataFrame a HTML para mejor visualización\n",
    "display(HTML(resultados_generales.to_html(escape=False)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba1dc4b1-b592-4515-916a-b98d289b138d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'rut' is both an index level and a column label, which is ambiguous.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9368\\1701699259.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[0mvalid_ages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcounts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcounts\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0.8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf_group\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_group\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'edad_ano_talla_hoy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_ages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;31m# Aplicar la función a cada grupo de 'rut'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m \u001b[0mddf_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mddf_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rut'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mget_top_80_percent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mddf_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;31m# Crear rangos para la variable edad_ano_talla_hoy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[0mmax_edad_ano_talla_hoy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mddf_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'edad_ano_talla_hoy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Convertir a entero y excluir NaN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\dask_expr\\_collection.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, by, group_keys, sort, observed, dropna, **kwargs)\u001b[0m\n\u001b[0;32m   2976\u001b[0m             raise ValueError(\n\u001b[0;32m   2977\u001b[0m                 \u001b[1;33mf\"\u001b[0m\u001b[1;33m`by` must be a column name or list of columns, got \u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2978\u001b[0m             \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2979\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2980\u001b[1;33m         return GroupBy(\n\u001b[0m\u001b[0;32m   2981\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2982\u001b[0m             \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2983\u001b[0m             \u001b[0mgroup_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroup_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\dask_expr\\_groupby.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, obj, by, group_keys, sort, observed, dropna, slice)\u001b[0m\n\u001b[0;32m   1538\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExpr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1539\u001b[0m             \u001b[1;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1540\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1541\u001b[0m         \u001b[1;31m# surface pandas errors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1542\u001b[1;33m         self._meta = self.obj._meta.groupby(\n\u001b[0m\u001b[0;32m   1543\u001b[0m             \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1544\u001b[0m             \u001b[0mgroup_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroup_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1545\u001b[0m             \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   9179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9180\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlevel\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mby\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9181\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"You have to supply one of 'by' and 'level'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 9183\u001b[1;33m         return DataFrameGroupBy(\n\u001b[0m\u001b[0;32m   9184\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9185\u001b[0m             \u001b[0mkeys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9186\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   1325\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup_keys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup_keys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdropna\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1328\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgrouper\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1329\u001b[1;33m             grouper, exclusions, obj = get_grouper(\n\u001b[0m\u001b[0;32m   1330\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1331\u001b[0m                 \u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1332\u001b[0m                 \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\groupby\\grouper.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[0;32m   1029\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_in_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# df.groupby('name')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgpr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1033\u001b[1;33m                     \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_label_or_level_ambiguity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1034\u001b[0m                 \u001b[0min_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgpr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgpr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m                     \u001b[1;31m# non-unique columns; raise here to get the name in the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1864\u001b[0m             msg = (\n\u001b[0;32m   1865\u001b[0m                 \u001b[1;33mf\"\u001b[0m\u001b[1;33m'\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m' is both \u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mlevel_article\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mlevel_type\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m level and \u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m                 \u001b[1;33mf\"\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mlabel_article\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m \u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mlabel_type\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m label, which is ambiguous.\u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1867\u001b[0m             \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1868\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: 'rut' is both an index level and a column label, which is ambiguous."
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "from dask import compute, delayed\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Convertir el DataFrame de pandas a Dask\n",
    "ddf_result = dd.from_pandas(df_result, npartitions=4)\n",
    "\n",
    "# Redondear los valores de frecuencia_mensual\n",
    "ddf_result['frecuencia_mensual_redondeada'] = ddf_result['frecuencia_mensual'].round()\n",
    "\n",
    "# Asignar rangos directamente según los valores redondeados de frecuencia_mensual\n",
    "ddf_result['frecuencia_mensual_rango'] = ddf_result['frecuencia_mensual_redondeada'].apply(lambda x: str(x) if x <= 10 else 'Mayor a 10', meta=('frecuencia_mensual_rango', 'str'))\n",
    "\n",
    "# Mapear rangos para la variable TICKET PROMEDIO\n",
    "def map_ticket_promedio(x):\n",
    "    if x <= 15000:\n",
    "        return '0-15000'\n",
    "    elif x <= 30000:\n",
    "        return '15001-30000'\n",
    "    elif x <= 45000:\n",
    "        return '30001-45000'\n",
    "    elif x <= 60000:\n",
    "        return '45001-60000'\n",
    "    else:\n",
    "        return 'Mayor a 60000'\n",
    "\n",
    "ddf_result['ticket_promedio_rango'] = ddf_result['ticket prom'].map(map_ticket_promedio, meta=('ticket_promedio_rango', 'str'))\n",
    "\n",
    "# Mapear rangos para la variable edad\n",
    "def map_edad(x):\n",
    "    if x <= 18:\n",
    "        return '0-18'\n",
    "    elif x <= 30:\n",
    "        return '19-30'\n",
    "    elif x <= 40:\n",
    "        return '31-40'\n",
    "    elif x <= 50:\n",
    "        return '41-50'\n",
    "    elif x <= 60:\n",
    "        return '51-60'\n",
    "    else:\n",
    "        return 'Mayor a 60'\n",
    "\n",
    "ddf_result['edad_rango'] = ddf_result['edad'].map(map_edad, meta=('edad_rango', 'str'))\n",
    "\n",
    "# Mapear rangos para la variable descuento\n",
    "def map_descuento(x):\n",
    "    if x <= 0.20:\n",
    "        return '0%-20%'\n",
    "    elif x <= 0.40:\n",
    "        return 'Mayor a 20% - 40%'\n",
    "    elif x <= 0.60:\n",
    "        return 'Mayor a 40% - 60%'\n",
    "    else:\n",
    "        return 'Mayor a 60%'\n",
    "\n",
    "ddf_result['descuento_rango'] = ddf_result['descuento'].map(map_descuento, meta=('descuento_rango', 'str'))\n",
    "\n",
    "# Mapear rangos para la variable TPC\n",
    "def map_tpc(x):\n",
    "    if x <= 1:\n",
    "        return '0-1'\n",
    "    else:\n",
    "        return 'Mayor a 1'\n",
    "\n",
    "ddf_result['tpc_rango'] = ddf_result['TPC'].map(map_tpc, meta=('tpc_rango', 'str'))\n",
    "\n",
    "# Eliminar valores NaN en 'edad_ano_talla_hoy' antes de agrupar y aplicar la función\n",
    "ddf_result = ddf_result.dropna(subset=['edad_ano_talla_hoy'])\n",
    "\n",
    "# Optimizar el cálculo de las edades según el 80% de las boletas\n",
    "def get_top_80_percent(df_group):\n",
    "    counts = df_group['edad_ano_talla_hoy'].value_counts(normalize=True).cumsum()\n",
    "    valid_ages = counts[counts <= 0.8].index.tolist()\n",
    "    return df_group[df_group['edad_ano_talla_hoy'].isin(valid_ages)]\n",
    "\n",
    "# Aplicar la función a cada grupo de 'rut'\n",
    "ddf_result = ddf_result.groupby('rut').apply(lambda df: get_top_80_percent(df.reset_index(drop=True)), meta=ddf_result.head())\n",
    "\n",
    "# Crear rangos para la variable edad_ano_talla_hoy\n",
    "max_edad_ano_talla_hoy = ddf_result['edad_ano_talla_hoy'].max().compute().astype(int)  # Convertir a entero y excluir NaN\n",
    "ddf_result['edad_ano_talla_hoy_rango'] = dd.cut(ddf_result['edad_ano_talla_hoy'], \n",
    "                                                bins=range(0, max_edad_ano_talla_hoy + 2),\n",
    "                                                labels=[str(i) for i in range(0, max_edad_ano_talla_hoy + 1)])\n",
    "\n",
    "# Función para formatear los porcentajes sin decimales ni puntos\n",
    "def format_percentage_without_decimals(column_values):\n",
    "    counts = column_values.value_counts()\n",
    "    return ', '.join([f\"{index}: {int(round((count / len(column_values)) * 100))}%\" for index, count in counts.items()])\n",
    "\n",
    "# Calcular los porcentajes de las variables categóricas, excluyendo valores nulos, NaN o vacíos\n",
    "def calculate_percentages(column):\n",
    "    return format_percentage_without_decimals(ddf_result[column].dropna())\n",
    "\n",
    "# Variables categóricas a procesar\n",
    "categorical_vars = [\n",
    "    'area_categorizada', 'genero_categorizado', 'canal_categorizado', \n",
    "    'frecuencia_mensual_rango', 'ticket_promedio_rango', 'edad_rango', \n",
    "    'descuento_rango', 'tpc_rango', 'edad_ano_talla_hoy_rango'\n",
    "]\n",
    "\n",
    "# Calcular porcentajes de todas las variables categóricas\n",
    "porcentajes_futures = [delayed(calculate_percentages)(var) for var in categorical_vars]\n",
    "porcentajes = compute(*porcentajes_futures)\n",
    "\n",
    "# Convertir resultados de porcentajes a un DataFrame\n",
    "porcentajes_df = pd.DataFrame({var: [pct] for var, pct in zip(categorical_vars, porcentajes)})\n",
    "\n",
    "# Calcular las estadísticas descriptivas de las variables numéricas seleccionadas\n",
    "estadisticas_numericas = ddf_result[['cantidad', 'edad', 'edad_ano_talla_hoy', 'ticket prom', 'frecuencia_mensual', 'TPC', 'descuento']].describe().compute().transpose()\n",
    "\n",
    "# Unir los DataFrames de distribuciones y estadísticas\n",
    "resultados_generales = pd.concat([estadisticas_numericas, porcentajes_df], axis=1).fillna('')\n",
    "\n",
    "# Convertir el DataFrame a HTML para mejor visualización\n",
    "display(HTML(resultados_generales.to_html(escape=False)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4043b18a-61b7-4e6f-9155-55cffb571179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>area_categorizada</th>\n",
       "      <th>genero_categorizado</th>\n",
       "      <th>canal_categorizado</th>\n",
       "      <th>frecuencia_mensual_rango</th>\n",
       "      <th>ticket_promedio_rango</th>\n",
       "      <th>edad_rango</th>\n",
       "      <th>descuento_rango</th>\n",
       "      <th>tpc_rango</th>\n",
       "      <th>edad_ano_talla_hoy_rango</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cantidad</th>\n",
       "      <td>842266.0</td>\n",
       "      <td>1.0171</td>\n",
       "      <td>0.151448</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edad</th>\n",
       "      <td>827116.0</td>\n",
       "      <td>36.392278</td>\n",
       "      <td>13.999513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edad_ano_talla_hoy</th>\n",
       "      <td>817471.0</td>\n",
       "      <td>6.365963</td>\n",
       "      <td>3.518286</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticket prom</th>\n",
       "      <td>842266.0</td>\n",
       "      <td>35561.692681</td>\n",
       "      <td>93850.42098</td>\n",
       "      <td>-15187.668488</td>\n",
       "      <td>19386.29</td>\n",
       "      <td>28989.59</td>\n",
       "      <td>41458.008375</td>\n",
       "      <td>6226299.9239</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>frecuencia_mensual</th>\n",
       "      <td>842266.0</td>\n",
       "      <td>1.914267</td>\n",
       "      <td>15.462368</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14049.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TPC</th>\n",
       "      <td>290925.0</td>\n",
       "      <td>90.992165</td>\n",
       "      <td>73.886458</td>\n",
       "      <td>2.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>71.5</td>\n",
       "      <td>125.5</td>\n",
       "      <td>363.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>descuento</th>\n",
       "      <td>842266.0</td>\n",
       "      <td>0.315583</td>\n",
       "      <td>0.222364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.369376</td>\n",
       "      <td>0.500001</td>\n",
       "      <td>0.928235</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>MIXTO: 355444, SOLO CALZADO: 308616, SOLO ROPA: 114323, SOLO ACCESORIO: 63883</td>\n",
       "      <td>GIRL: 324909, BOY: 274167, MIXTO: 219520, Sin Genero: 23384, WOMAN: 19, MEN: 6</td>\n",
       "      <td>OFFLINE: 715081, MIXTO: 64049, ONLINE: 63136</td>\n",
       "      <td>1: 521446, 2: 160816, 3: 69465, 4: 35191, 5: 19791, 6: 12011, 7: 7426, Mayor a 10: 5967, 8: 4831, 9: 3199, 10: 2123</td>\n",
       "      <td>15001-30000: 329309, 30001-45000: 221507, 0-15000: 124388, 45001-60000: 88203, Mayor a 60000: 78858</td>\n",
       "      <td>31-40: 264598, 19-30: 234905, 41-50: 151917, 51-60: 73769, Mayor a 60: 53528, 0-18: 43448</td>\n",
       "      <td>Mayor a 40% - 60%: 288936, 0%-20%: 256083, Mayor a 20% - 40%: 205751, Mayor a 60%: 91496</td>\n",
       "      <td>Mayor a 1: 290925, 0-1: 0</td>\n",
       "      <td>1: 112120, 2: 98130, 4: 89950, 3: 74649, 7: 67469, 6: 63885, 5: 63644, 10: 57759, 8: 48205, 9: 40994, 11: 40471, 12: 34874, 0: 16299, 13: 6153, 17: 1455, 14: 1255, 15: 104, 16: 55, 18: 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Redondear los valores de frecuencia_mensual\n",
    "df_result['frecuencia_mensual_redondeada'] = df_result['frecuencia_mensual'].apply(lambda x: round(x))\n",
    "\n",
    "# Asignar rangos directamente según los valores redondeados de frecuencia_mensual\n",
    "df_result['frecuencia_mensual_rango'] = df_result['frecuencia_mensual_redondeada'].apply(lambda x: str(x) if x <= 10 else 'Mayor a 10')\n",
    "\n",
    "# Crear rangos para la variable TICKET PROMEDIO\n",
    "df_result['ticket_promedio_rango'] = pd.cut(df_result['ticket prom'], bins=[0, 15000, 30000, 45000, 60000, float('inf')],\n",
    "                                            labels=['0-15000', '15001-30000', '30001-45000', '45001-60000', 'Mayor a 60000'])\n",
    "\n",
    "# Crear rangos para la variable edad, excluyendo valores nulos\n",
    "df_result['edad_rango'] = pd.cut(df_result['edad'].dropna(), bins=[0, 18, 30, 40, 50, 60, float('inf')],\n",
    "                                 labels=['0-18', '19-30', '31-40', '41-50', '51-60', 'Mayor a 60'])\n",
    "\n",
    "# Ajustar rangos para la variable descuento según tu requerimiento\n",
    "df_result['descuento_rango'] = pd.cut(df_result['descuento'], bins=[-0.01, 0.20, 0.40, 0.60, float('inf')],\n",
    "                                      labels=['0%-20%', 'Mayor a 20% - 40%', 'Mayor a 40% - 60%', 'Mayor a 60%'])\n",
    "\n",
    "# Crear rangos para la variable TPC\n",
    "df_result['tpc_rango'] = pd.cut(df_result['TPC'], bins=[0, 1, float('inf')],\n",
    "                                labels=['0-1', 'Mayor a 1'])\n",
    "\n",
    "# Crear rangos para la variable edad_ano_talla_hoy, excluyendo valores nulos\n",
    "max_edad_ano_talla_hoy = int(df_result['edad_ano_talla_hoy'].max())  # Convertir a entero\n",
    "df_result['edad_ano_talla_hoy_rango'] = pd.cut(df_result['edad_ano_talla_hoy'].dropna(), \n",
    "                                               bins=range(0, max_edad_ano_talla_hoy + 2),\n",
    "                                               labels=[str(i) for i in range(0, max_edad_ano_talla_hoy + 1)])\n",
    "\n",
    "# Función para formatear los conteos\n",
    "def format_count_without_decimals(column_values):\n",
    "    counts = column_values.value_counts()\n",
    "    return ', '.join([f\"{index}: {count}\" for index, count in counts.items()])\n",
    "\n",
    "# Calcular los conteos de las variables categóricas, excluyendo valores nulos, NaN o vacíos\n",
    "conteos_area = format_count_without_decimals(df_result['area_categorizada'].dropna())\n",
    "conteos_genero = format_count_without_decimals(df_result['genero_categorizado'].dropna())\n",
    "conteos_canal = format_count_without_decimals(df_result['canal_categorizado'].dropna())\n",
    "conteos_frecuencia_mensual = format_count_without_decimals(df_result['frecuencia_mensual_rango'].dropna())\n",
    "conteos_ticket_promedio = format_count_without_decimals(df_result['ticket_promedio_rango'].dropna())\n",
    "conteos_edad = format_count_without_decimals(df_result['edad_rango'])\n",
    "conteos_descuento = format_count_without_decimals(df_result['descuento_rango'].dropna())\n",
    "conteos_tpc = format_count_without_decimals(df_result['tpc_rango'].dropna())\n",
    "conteos_edad_ano_talla_hoy = format_count_without_decimals(df_result['edad_ano_talla_hoy_rango'])\n",
    "\n",
    "# Calcular las estadísticas descriptivas de las variables numéricas seleccionadas\n",
    "estadisticas_numericas = df_result[['cantidad', 'edad', 'edad_ano_talla_hoy', 'ticket prom', 'frecuencia_mensual', 'TPC', 'descuento']].describe().transpose()\n",
    "\n",
    "# Crear un DataFrame con las distribuciones y estadísticas\n",
    "distribuciones = pd.DataFrame({\n",
    "    'area_categorizada': [conteos_area],\n",
    "    'genero_categorizado': [conteos_genero],\n",
    "    'canal_categorizado': [conteos_canal],\n",
    "    'frecuencia_mensual_rango': [conteos_frecuencia_mensual],\n",
    "    'ticket_promedio_rango': [conteos_ticket_promedio],\n",
    "    'edad_rango': [conteos_edad],\n",
    "    'descuento_rango': [conteos_descuento],\n",
    "    'tpc_rango': [conteos_tpc],\n",
    "    'edad_ano_talla_hoy_rango': [conteos_edad_ano_talla_hoy]\n",
    "})\n",
    "\n",
    "# Unir los DataFrames de distribuciones y estadísticas\n",
    "resultados_generales = pd.concat([estadisticas_numericas, distribuciones], axis=1).fillna('')\n",
    "\n",
    "# Convertir el DataFrame a HTML para mejor visualización\n",
    "display(HTML(resultados_generales.to_html(escape=False)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3222b0f9-b830-41f4-b4c4-b38a1b3396c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rango: 31-40, Porcentaje: 32.18%\n",
      "Rango: 19-30, Porcentaje: 28.57%\n",
      "Rango: 41-50, Porcentaje: 18.48%\n",
      "Rango: 51-60, Porcentaje: 8.97%\n",
      "Rango: Mayor a 60, Porcentaje: 6.51%\n",
      "Rango: 0-18, Porcentaje: 5.28%\n"
     ]
    }
   ],
   "source": [
    "# Nuevos rangos con sus valores correspondientes\n",
    "rangos_nuevos = {\n",
    "    '31-40': 264598,\n",
    "    '19-30': 234905,\n",
    "    '41-50': 151917,\n",
    "    '51-60': 73769,\n",
    "    'Mayor a 60': 53528,\n",
    "    '0-18': 43448\n",
    "}\n",
    "\n",
    "# Total de todos los valores en los nuevos rangos\n",
    "total_nuevos = sum(rangos_nuevos.values())\n",
    "\n",
    "# Calcular los porcentajes para los nuevos rangos\n",
    "porcentajes_rangos = {rango: (cantidad / total_nuevos) * 100 for rango, cantidad in rangos_nuevos.items()}\n",
    "\n",
    "# Ordenar los rangos de mayor a menor\n",
    "rangos_ordenados = sorted(porcentajes_rangos.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Mostrar los resultados\n",
    "for rango, porcentaje in rangos_ordenados:\n",
    "    print(f\"Rango: {rango}, Porcentaje: {porcentaje:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b41adfd-7963-4309-ad8d-7137e31bcb51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0084b04-7968-45b3-ad2a-9af20ca41630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afc9981-a3b2-450c-adc4-bedb8fc426ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
